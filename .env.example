# For TGI on DigitalOcean
LLM_ENDPOINT=https://llm.example.com
# For local CPU quick test with Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=tinyllama:1.1b 
