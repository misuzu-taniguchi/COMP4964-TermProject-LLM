# For TGI on DigitalOcean
LLM_ENDPOINT=https://llm.example.com
# For local CPU quick test with Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b-instruct-q4_K_M
